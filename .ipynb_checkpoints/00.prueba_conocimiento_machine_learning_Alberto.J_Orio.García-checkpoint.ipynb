{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46dd5a6-ece1-48d5-93c0-c286c805c204",
   "metadata": {},
   "source": [
    "# Alberto J. Orio García."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56829200",
   "metadata": {},
   "source": [
    "## Prueba de Conocimiento: Machine Learning & NLP\n",
    "\n",
    "Usando el dataset de **`Tweets.csv`** y utilizando métodos de procesamiento de datos de **`NLP`**, desarrolla un modelo de predicción sobre la columna de **`sentiment`**.\n",
    "\n",
    "- Usa diferentes modelos de clasificación y compara sus métricas y el tiempo de ejecución de cada uno.\n",
    "- Retorna un **`DataFrame`** con los resultados (metricas) de todos los modelos.\n",
    "- Selecciona el mejor modelo y aplica **`GridSearch()`** para encontrar los mejores parámetros.\n",
    "- Usa algoritmos de **`PCA`** o de **`SMOTE`** si consideras que es necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c924d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Bag-of-Words y TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Normalizacion\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Train, Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "# Clasificadores\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Validacion\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6565c41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1             I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                       my boss is bullying me...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Tweets.csv\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8449c4-473b-49ce-a479-3bb322ccc5fa",
   "metadata": {},
   "source": [
    "### Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715f2f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0                    I`d have responded, if I were going   neutral\n",
       "1          Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                              my boss is bullying me...  negative\n",
       "3                         what interview! leave me alone  negative\n",
       "4       Sons of ****, why couldn`t they put them on t...  negative\n",
       "...                                                  ...       ...\n",
       "27476   wish we could come see u on Denver  husband l...  negative\n",
       "27477   I`ve wondered about rake to.  The client has ...  negative\n",
       "27478   Yay good for both of you. Enjoy the break - y...  positive\n",
       "27479                         But it was worth it  ****.  positive\n",
       "27480     All this flirting going on - The ATG smiles...   neutral\n",
       "\n",
       "[27481 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Las columnas texID y selected_text no son necesarias.\n",
    "# Esto es para eliminarlas.\n",
    "\n",
    "df.drop(['textID', 'selected_text',], axis = 1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464b815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         27480\n",
       "sentiment    27481\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para averiguar el número de elementos que no son NaN.\n",
    "# Se ve que en la columna text hay un NaN.\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae96fbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0                    I`d have responded, if I were going   neutral\n",
       "1          Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                              my boss is bullying me...  negative\n",
       "3                         what interview! leave me alone  negative\n",
       "4       Sons of ****, why couldn`t they put them on t...  negative\n",
       "...                                                  ...       ...\n",
       "27476   wish we could come see u on Denver  husband l...  negative\n",
       "27477   I`ve wondered about rake to.  The client has ...  negative\n",
       "27478   Yay good for both of you. Enjoy the break - y...  positive\n",
       "27479                         But it was worth it  ****.  positive\n",
       "27480     All this flirting going on - The ATG smiles...   neutral\n",
       "\n",
       "[27480 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para eliminar ese NaN (en realidad, esto elimina todas las filas\n",
    "# en las que hubiera al menos un valor NaN).\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d13b99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para ver el tamaño de los datos: 27.480 filas\n",
    "# y 2 columnas. Viendo esto, seguramente no sea\n",
    "# necesario realizar PCA para reducir la dimensionalidad.\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e177fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     11117\n",
       "positive     8582\n",
       "negative     7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para averiguar el número de valores de cada tipo.\n",
    "# Se ve que no existe un desbalance significativo, por \n",
    "# lo que no será necesario aplicar SMOTE.\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528a1b1d-32c0-44bf-a5c6-f7d688bafce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11117\n",
       "1     8582\n",
       "2     7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para sustituir los valores neutral, positive y negative\n",
    "# por números (0, 1 y 2, respectivamente), y luego poder \n",
    "# trabajar con ellos en modelos de predicción.\n",
    "\n",
    "df['sentiment'].replace('neutral', 0, inplace = True)\n",
    "df['sentiment'].replace('positive', 1, inplace = True)\n",
    "df['sentiment'].replace('negative', 2, inplace = True)\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad83a739-436b-4129-8f60-5959ef26b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener todos los textos en una lista.\n",
    "\n",
    "lista_textos = df['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6058e996-15db-4596-af64-0b992b9175ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' I`d have responded, if I were going',\n",
       " ' Sooo SAD I will miss you here in San Diego!!!',\n",
       " 'my boss is bullying me...',\n",
       " ' what interview! leave me alone',\n",
       " ' Sons of ****, why couldn`t they put them on the releases we already bought',\n",
       " 'http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth',\n",
       " '2am feedings for the baby are fun when he is all smiles and coos',\n",
       " 'Soooo high',\n",
       " ' Both of you',\n",
       " ' Journey!? Wow... u just became cooler.  hehe... (is that possible!?)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_textos[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340bb13d-49fe-4ef8-853a-145c7fd4ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para agrupar los stopwords, o palabras carentes de\n",
    "# significado e importancia, que serán excluidas del análisis.\n",
    "# Se le añaden los saltos de línea y los asteriscos, que\n",
    "# probablemente representan insultos.\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append('<br />')\n",
    "stopwords.append('*')\n",
    "stopwords.append('**')\n",
    "stopwords.append('***')\n",
    "stopwords.append('****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f7621a2-fcb4-4a18-aa89-c78f19520183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con esta función, se pasan los textos a minúsculas, se\n",
    "# descartan las palabras cortas, y se eliminan los stopwords\n",
    "# definidos anteriormente.\n",
    "\n",
    "def depurar(lista, stopwords):\n",
    "    tokens_depurados = list()\n",
    "\n",
    "    for texto in lista:\n",
    "        \n",
    "        tokens_textos = list()\n",
    "        tokens = nltk.word_tokenize(text = texto.lower(), language = 'english')\n",
    "        \n",
    "        for token in tokens:\n",
    "            if (token not in stopwords) and (len(token) > 2):\n",
    "                tokens_textos.append(token)\n",
    "                \n",
    "        tokens_depurados.append(tokens_textos) \n",
    "    \n",
    "    return tokens_depurados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abcb5090-05fb-4252-8f14-7e267887277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Utilizando la función previa, se guarda en una \n",
    "# variable la lista de textos ya limpios.\n",
    "\n",
    "lista_textos = depurar(lista_textos, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01741a0-8447-4a66-a000-f04b78d5b91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['responded', 'going'],\n",
       " ['sooo', 'sad', 'miss', 'san', 'diego'],\n",
       " ['boss', 'bullying', '...'],\n",
       " ['interview', 'leave', 'alone'],\n",
       " ['sons', 'put', 'releases', 'already', 'bought'],\n",
       " ['http',\n",
       "  '//www.dothebouncy.com/smf',\n",
       "  'shameless',\n",
       "  'plugging',\n",
       "  'best',\n",
       "  'rangers',\n",
       "  'forum',\n",
       "  'earth'],\n",
       " ['2am', 'feedings', 'baby', 'fun', 'smiles', 'coos'],\n",
       " ['soooo', 'high'],\n",
       " [],\n",
       " ['journey', 'wow', '...', 'became', 'cooler', 'hehe', '...', 'possible']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_textos[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5a11dc7-4ff6-420d-927f-afccd02d9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para quedarse solo con las raices de las palabras,\n",
    "# conservando, eso sí, su significado.\n",
    "\n",
    "def lematizar(lista):\n",
    "    \n",
    "    textos = list()\n",
    "    \n",
    "    for texto in lista:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        textos.append(\" \".join([lemmatizer.lemmatize(word) for word in texto]))\n",
    "\n",
    "    return textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea6141a8-3435-4903-bc5f-ebc347d8821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# De nuevo, se guarda en una variable\n",
    "# la lista de textos ya tratados, usando la\n",
    "# función definida en la celda anterior.\n",
    "\n",
    "lista_textos = lematizar(lista_textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684b047d-dbb4-46f3-a968-f576d061ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['responded going',\n",
       " 'sooo sad miss san diego',\n",
       " 'bos bullying ...',\n",
       " 'interview leave alone',\n",
       " 'son put release already bought',\n",
       " 'http //www.dothebouncy.com/smf shameless plugging best ranger forum earth',\n",
       " '2am feeding baby fun smile coo',\n",
       " 'soooo high',\n",
       " '',\n",
       " 'journey wow ... became cooler hehe ... possible']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_textos[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6630be8-f31c-497e-a23f-b937a436cf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27480x24212 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 184815 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para transformar el texto en números, en\n",
    "# forma de matriz, donde las columnas la forman \n",
    "# las palabras que aparecen en el texto, y las filas\n",
    "# las veces que aparecen en el texto.\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "bag = count_vectorizer.fit_transform(lista_textos)\n",
    "\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f3afd39-5ce2-4b9a-bf41-21d25d297cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se utiliza TF-IDF para reducir el peso de aquellas\n",
    "# palabras que aparecen mucho. Se realiza sobre la operación\n",
    "# anterior, se entrena y transforma, y se guarda en la\n",
    "# variable bag, igual que antes. Adicionalemente, se\n",
    "# reduce su precisión a 2 decimales, y se pasan los datos\n",
    "# en forma de array (por ser más difícil trabajar con matrices sparse).\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "np.set_printoptions(precision = 2)\n",
    "\n",
    "bag = tfidf.fit_transform(bag).toarray()\n",
    "\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24bac33e-9ce0-4563-a27c-51c22e1003b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21984, 24212), y_train: (21984,)\n",
      "X_test: (5496, 24212),  y_test: (5496,)\n"
     ]
    }
   ],
   "source": [
    "# Para separar los datos, ya tratados y pasados a números,\n",
    "# en X e y, y en conjuntos de entranamiento y de test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bag, df['sentiment'].values, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape},  y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b432154-63e1-49ab-b621-60cbd8ee4640",
   "metadata": {},
   "source": [
    "### Modelos de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "395c11de-5db5-40a2-bf75-c99923d3cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_modelos = [KNeighborsClassifier(n_neighbors = 3),\n",
    "                RadiusNeighborsClassifier(radius = 0.8, outlier_label = \"most_frequent\"),\n",
    "                NearestCentroid(metric = \"euclidean\"), \n",
    "                GaussianNB(),\n",
    "                LogisticRegression(),\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                SVC(),\n",
    "                AdaBoostClassifier(),\n",
    "                GradientBoostingClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2a1ccf9-ccdd-4b91-9472-0687b3e35d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar(lista_modelos, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    for modelo in lista_modelos:\n",
    "        print(modelo)\n",
    "\n",
    "        modelo.fit(X_train, y_train)\n",
    "\n",
    "        yhat = modelo.predict(X_test)\n",
    "        \n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Accuracy:\"     , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        #print(\"ROC AUC:\"     , roc_auc_score(y_test, yhat)) Da error: multi_class must be in ('ovo', 'ovr')\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
    "        print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c0fb950-826c-446e-8ac8-d80d7b9f5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "Jaccard Index: 0.2154748028119092\n",
      "Accuracy: 0.46033478893740903\n",
      "Precisión: 0.6520297086850556\n",
      "Sensibilidad: 0.39765532854077595\n",
      "F1-score: 0.3316919988760159\n",
      "Confusion Matrix:\n",
      " [[2149   44   43]\n",
      " [1435  240   13]\n",
      " [1419   12  141]]\n",
      "****************************************************************************************************\n",
      "RadiusNeighborsClassifier(outlier_label='most_frequent', radius=0.8)\n",
      "Jaccard Index: 0.1866682757702561\n",
      "Accuracy: 0.4410480349344978\n",
      "Precisión: 0.6491423413207852\n",
      "Sensibilidad: 0.3742180405080268\n",
      "F1-score: 0.28476744260531295\n",
      "Confusion Matrix:\n",
      " [[2183   27   26]\n",
      " [1523  159    6]\n",
      " [1479   11   82]]\n",
      "****************************************************************************************************\n",
      "NearestCentroid()\n",
      "Jaccard Index: 0.4362057189917848\n",
      "Accuracy: 0.6153566229985444\n",
      "Precisión: 0.6474934634811107\n",
      "Sensibilidad: 0.5961147277746609\n",
      "F1-score: 0.6067286662247192\n",
      "Confusion Matrix:\n",
      " [[1712  251  273]\n",
      " [ 690  907   91]\n",
      " [ 694  115  763]]\n",
      "****************************************************************************************************\n",
      "GaussianNB()\n",
      "Jaccard Index: 0.20634374791808505\n",
      "Accuracy: 0.3571688500727802\n",
      "Precisión: 0.3966652843069424\n",
      "Sensibilidad: 0.3905876075836776\n",
      "F1-score: 0.3358927314093325\n",
      "Confusion Matrix:\n",
      " [[ 282  413 1541]\n",
      " [ 193  542  953]\n",
      " [ 190  243 1139]]\n",
      "****************************************************************************************************\n",
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Index: 0.5192834933301474\n",
      "Accuracy: 0.6841339155749636\n",
      "Precisión: 0.7061876842617387\n",
      "Sensibilidad: 0.6723528074420916\n",
      "F1-score: 0.6821958030667413\n",
      "Confusion Matrix:\n",
      " [[1714  244  278]\n",
      " [ 457 1167   64]\n",
      " [ 614   79  879]]\n",
      "****************************************************************************************************\n",
      "DecisionTreeClassifier()\n",
      "Jaccard Index: 0.4949042299094277\n",
      "Accuracy: 0.6610262008733624\n",
      "Precisión: 0.661128751738762\n",
      "Sensibilidad: 0.6610804400510331\n",
      "F1-score: 0.6609191489583254\n",
      "Confusion Matrix:\n",
      " [[1451  365  420]\n",
      " [ 330 1229  129]\n",
      " [ 463  156  953]]\n",
      "****************************************************************************************************\n",
      "RandomForestClassifier()\n",
      "Jaccard Index: 0.5425973984788003\n",
      "Accuracy: 0.7050582241630277\n",
      "Precisión: 0.7168076933231268\n",
      "Sensibilidad: 0.6971489195985289\n",
      "F1-score: 0.7018910837819753\n",
      "Confusion Matrix:\n",
      " [[1676  309  251]\n",
      " [ 334 1303   51]\n",
      " [ 539  137  896]]\n",
      "****************************************************************************************************\n",
      "SVC()\n",
      "Jaccard Index: 0.5224755466602719\n",
      "Accuracy: 0.6905021834061136\n",
      "Precisión: 0.7317838651606272\n",
      "Sensibilidad: 0.6714927244506872\n",
      "F1-score: 0.6845134480575826\n",
      "Confusion Matrix:\n",
      " [[1852  194  190]\n",
      " [ 512 1139   37]\n",
      " [ 695   73  804]]\n",
      "****************************************************************************************************\n",
      "AdaBoostClassifier()\n",
      "Jaccard Index: 0.47393455647380933\n",
      "Accuracy: 0.6557496360989811\n",
      "Precisión: 0.6994179436912936\n",
      "Sensibilidad: 0.6319341877688385\n",
      "F1-score: 0.6358178382695402\n",
      "Confusion Matrix:\n",
      " [[1822  268  146]\n",
      " [ 450 1204   34]\n",
      " [ 875  119  578]]\n",
      "****************************************************************************************************\n",
      "GradientBoostingClassifier()\n",
      "Jaccard Index: 0.4676533283975712\n",
      "Accuracy: 0.6502911208151383\n",
      "Precisión: 0.7118058396102231\n",
      "Sensibilidad: 0.6228668748459454\n",
      "F1-score: 0.6334657432744171\n",
      "Confusion Matrix:\n",
      " [[1902  196  138]\n",
      " [ 611 1044   33]\n",
      " [ 853   91  628]]\n",
      "****************************************************************************************************\n",
      "Wall time: 15h 11min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clasificar(lista_modelos, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f327d8-1c7f-4eef-a422-774e7e0b0edf",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f6dce93-b82c-41c3-a8b3-091cfeffe776",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.17 GiB for an array with shape (17587, 24212) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 585, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 211, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 344, in _safe_indexing\n    return _array_indexing(X, indices, indices_dtype, axis=axis)\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 179, in _array_indexing\n    return array[key] if axis == 0 else array[:, key]\n  File \"C:\\Users\\pccom\\anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py\", line 334, in __getitem__\n    res = super(memmap, self).__getitem__(index)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.17 GiB for an array with shape (17587, 24212) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.17 GiB for an array with shape (17587, 24212) and data type float64"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Echando un vistazo a las métricas de los clasificadores,\n",
    "# parece que el mejor modelo para predecir la columna sentiment\n",
    "# es el RandomForestClassifier (tiene la mayor Accuracy, y en\n",
    "# el resto de métricas está entre las mejores o tiene la mejor).\n",
    "# Por lo tanto, se aplicará GridSearch a RandomForestClassifier\n",
    "# para buscar los mejores parámetros, en base a mejorar la Accuracy.\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "params = {\"n_estimators\"           : [100, 200],\n",
    "          \"criterion\"              : [\"gini\", \"entropy\"],\n",
    "          \"max_depth\"              : [3, 4, 5],\n",
    "          \"max_features\"           : [2, 3],\n",
    "          \"max_leaf_nodes\"         : [8],\n",
    "          \"min_impurity_decrease\"  : [0.02, 0.3],\n",
    "          \"min_samples_split\"      : [2, 5]}\n",
    "\n",
    "scorers = {\"f1_macro\", \"accuracy\", \"recall_macro\"}\n",
    "\n",
    "grid_solver = GridSearchCV(estimator  = model    , \n",
    "                           param_grid = params   , \n",
    "                           scoring    = scorers  ,\n",
    "                           cv         = 5        ,\n",
    "                           refit      = \"accuracy\",\n",
    "                           n_jobs     = -1        )\n",
    "\n",
    "model_result = grid_solver.fit(X_train, y_train)\n",
    "\n",
    "print(model_result.cv_results_[\"mean_test_recall_macro\"].mean())\n",
    "print(model_result.cv_results_[\"mean_test_f1_macro\"].mean())\n",
    "print(model_result.cv_results_[\"mean_test_accuracy\"].mean())\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(model_result.best_score_)\n",
    "print(model_result.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
